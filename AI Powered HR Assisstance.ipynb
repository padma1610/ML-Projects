{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae767012-b175-405e-9bca-61e6d9678bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import openai\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3187082-59c1-4926-8641-96932b043e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"your-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c46f06-942c-4a7b-94a2-cb63acb92711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read PDF files\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956b8274-b770-4388-868f-829996695f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# ChatOpenAI: for using OpenAI's chat models like GPT-3.5 Turbo.\n",
    "# OpenAIEmbeddings: for generating embeddings from text using OpenAI's models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313baae4-a710-4472-a5a4-3f4af508059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "# FAISS: for efficient similarity search and clustering of dense vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be826be0-26f1-46cb-8507-12a8f161a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create divided text chunks using a text splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5462a323-447b-4bf8-8690-a3c1787cc81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 8\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"Dataset/the_nestle_hr_policy_pdf_2012.pdf\"\n",
    "\n",
    "# Step 3: Load the PDF document using PyPDFLoader\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "# Print the number of documents loaded\n",
    "print(f\"Number of documents loaded: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "109d3d6c-f6b1-4668-8512-b7dc315214ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks created: 20\n"
     ]
    }
   ],
   "source": [
    "# Split PDF text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Print the number of text chunks created\n",
    "print(f\"Number of text chunks created: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170c51e7-3528-4749-a653-f4ec05cf2719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenAI embedding model: text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create embeddings for each chunk using OpenAI\n",
    "embeddings = OpenAIEmbeddings(api_key=openai.api_key) # text-embedding-ada-002\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=openai_api_key)\n",
    "\n",
    "# Print the embedding model being used\n",
    "print(f\"Using OpenAI embedding model: {embeddings.model}\") # Display the model being used for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f256170e-15b5-4787-a686-0cc174912b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store chunks in FAISS vector store\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4041ffef-41c0-4894-baac-7a4bee856f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GPT-4 Turbo via LangChain\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.3,\n",
    "    api_key=openai.api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "293c4518-df4d-42d8-8a9e-49770efb7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import messages_from_dict, messages_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08004008-6ee3-464f-b2d8-ba4b0b22d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9efe97df-e94c-4797-a620-b7ca52e5af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08fbb800-9682-4c10-b7c1-ecebf5df3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nestle_chatbot_reply(message, history):\n",
    "    if not message:\n",
    "        return history, \"\"\n",
    "\n",
    "    if message.strip().lower() == \"clear\":\n",
    "        memory.clear()\n",
    "        return [], \"\"\n",
    "\n",
    "    response = qa_chain.invoke({\"question\": message})\n",
    "    answer = response[\"answer\"]\n",
    "\n",
    "    # history format: list of {\"role\": ..., \"content\": ...}\n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    return history, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb536e6f-90e2-4c6c-90d7-9927308eb588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ðŸ¤– HR Document Chatbot\")\n",
    "    chatbot = gr.Chatbot(type = \"messages\")\n",
    "    msg = gr.Textbox(placeholder=\"Ask a question about HR policy...\")\n",
    "    send_btn = gr.Button(\"Send\")\n",
    "    clear_btn = gr.Button(\"Clear Chat\")\n",
    "\n",
    "    msg.submit(nestle_chatbot_reply, inputs=[msg, chatbot], outputs=[chatbot, msg])\n",
    "    send_btn.click(nestle_chatbot_reply, inputs=[msg, chatbot], outputs=[chatbot, msg])\n",
    "    clear_btn.click(lambda: ([], \"\"), None, outputs=[chatbot, msg])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b54106-d801-45a6-b1e5-e460b151e95c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
